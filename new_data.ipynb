{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "import shap\n",
    "import pickle\n",
    "np.random.seed(0)\n",
    "\n",
    "def select_df(df, lang='en', withheld='DE', exclude_fully_blocked_users=False, only_include_fully_blocked_users=False, exclude_certain_retweet_targets=None):\n",
    "    if withheld is not None:\n",
    "        new_df = df[df['withheld'].fillna('').str.contains(f\"'{withheld}'\")]\n",
    "    else:\n",
    "        new_df = df\n",
    "    new_df = new_df.loc[new_df['lang'] == lang]\n",
    "\n",
    "    if exclude_fully_blocked_users:\n",
    "        import pandas as pd\n",
    "        user_df = pd.read_csv('/home/public/twitter_politics/censorship/data/paper_data/users.csv')\n",
    "        new_df = new_df[~new_df['author_id'].isin(user_df['id'].values.tolist())]\n",
    "        return new_df\n",
    "    \n",
    "    if only_include_fully_blocked_users:\n",
    "        # an author_id list\n",
    "        new_df = new_df[new_df['author_id'].isin(only_include_fully_blocked_users)]\n",
    "\n",
    "        return new_df\n",
    "    \n",
    "    if exclude_certain_retweet_targets:\n",
    "        for exclude_target in exclude_certain_retweet_targets:\n",
    "            new_df = new_df[~new_df['text'].str.contains(f\"RT @{exclude_target}\")]\n",
    "\n",
    "    return new_df\n",
    "out_str = '/nfs/turbo/coe-vvh/ljr/Censorship/data/dataset_test_p.csv'\n",
    "data = pd.read_csv(out_str, engine='python', index_col=0)\n",
    "data_out = select_df(data, lang='en', withheld=None)\n",
    "data_out.to_csv(out_str[:-4] + '_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-02-18 14:15:56.139460: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 14:15:57.391120: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-18 14:15:57.920434: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-18 14:16:01.515426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2023-02-18 14:16:01.516423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2023-02-18 14:16:01.516439: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --dataset_df_dir data/ --splits_filename dataset_train_p_en.csv dataset_val_p_en.csv dataset_test_p_en.csv --text_col full_text_proc --y_col censored --class_weight automatic --seed 42 --model_save_dir models/ --log_dir log/ --iter_time_span 1000 --csv_output_path output/roberta-base-proc-new-p-en.csv --pretrained_model roberta-base --n_epochs 1 --output_type binary --lr 1e-5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d173519db91affa0419ef34ac2e0efa9beec21f626fb3d1d701decf56cf78fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
